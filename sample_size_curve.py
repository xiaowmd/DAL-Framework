import numpy as np
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt
import json
import os
# --- æ ¸å¿ƒå‡½æ•°ï¼šæ›²çº¿æ‹Ÿåˆæ¨¡å‹ ---

def inverse_power_law(x, a, b, c):
    """
    å®šä¹‰é€†å¹‚å¾‹æ¨¡å‹å‡½æ•°ã€‚
    è¿™æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„å­¦ä¹ æ›²çº¿æ¨¡å‹ï¼Œè¡¨ç¤ºæ€§èƒ½ä¼šéšç€æ ·æœ¬é‡çš„å¢åŠ è€Œé¥±å’Œã€‚
    - a: æœ€ç»ˆçš„é¥±å’Œæ€§èƒ½çš„ä¸Šé™ï¼ˆç†è®ºæœ€å¤§F1å€¼ï¼‰
    - b: å­¦ä¹ é€Ÿç‡ç›¸å…³çš„ç³»æ•°
    - c: æ›²çº¿çš„å¼¯æ›²ç¨‹åº¦
    æ¨¡å‹å½¢å¼: F1(x) = a - b * x^c
    """
    return a - b * np.power(x, c)

def weighted_curve_fit(x_data, y_data):
    """
    å®šä¹‰éçº¿æ€§åŠ æƒæœ€å°äºŒä¹˜æ‹Ÿåˆå‡½æ•°ã€‚
    å¢åŠ äº†å‚æ•°è¾¹ç•Œä»¥ç¡®ä¿æ‹Ÿåˆæ›²çº¿æ˜¯å•è°ƒé€’å¢çš„ã€‚
    """
    if len(x_data) < 3:
        return None, None
    m = len(x_data)
    weights = np.array([(j + 1) / m for j in range(m)])
    initial_guess = [np.max(y_data), 0.1, -0.1]
    
    # --- ä¿®æ”¹éƒ¨åˆ†ï¼šå¢åŠ å‚æ•°è¾¹ç•Œ ---
    # çº¦æŸ a (æœ€å¤§F1) åœ¨ [å½“å‰æœ€å¤§F1, 1.05] ä¹‹é—´
    # çº¦æŸ b (ç¼©æ”¾ç³»æ•°) > 0
    # çº¦æŸ c (æŒ‡æ•°) < 0
    # è¿™å°†å¼ºåˆ¶æ‹Ÿåˆå‡½æ•°ä¸ºå•è°ƒé€’å¢çš„é¥±å’Œæ›²çº¿
    lower_bounds = [np.min(y_data), 0, -np.inf]
    upper_bounds = [1.05, np.inf, 0]
    bounds = (lower_bounds, upper_bounds)
    
    try:
        popt, pcov = curve_fit(
            inverse_power_law, 
            x_data, 
            y_data, 
            p0=initial_guess, 
            sigma=1/weights, 
            maxfev=10000,
            bounds=bounds  # åº”ç”¨è¾¹ç•Œ
        )
        return popt, pcov
    except RuntimeError:
        print(f"Warning: Curve fitting failed for data x={x_data}, y={y_data}")
        return None, None

# --- æ–°å¢å‡½æ•°ï¼šé¢„æµ‹æ ·æœ¬é‡ ---

def predict_sample_size(popt, target_f1):
    """
    æ ¹æ®æ‹Ÿåˆå‚æ•°é¢„æµ‹è¾¾åˆ°ç›®æ ‡F1åˆ†æ•°æ‰€éœ€çš„æ ·æœ¬é‡ã€‚
    ä» y = a - b * x^c  è§£å‡º x:  x = ((a - y) / b)^(1/c)
    """
    a, b, c = popt
    if c == 0 or b == 0:
        return None
    if target_f1 >= a:
        return ">= Max"
    base = (a - target_f1) / b
    if base <= 0:
        return None
    try:
        predicted_x = (base) ** (1 / c)
        return predicted_x
    except (ValueError, OverflowError):
        return None

# --- æ•°æ®å¤„ç†å‡½æ•° ---

def read_experiment_results(file_path):
    """
    ä»æŒ‡å®šçš„JSONæ–‡ä»¶è·¯å¾„è¯»å–å®éªŒç»“æœã€‚
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Error: The file {file_path} was not found.")
    
    with open(file_path, 'r', encoding='utf-8') as json_file:
        try:
            results = json.load(json_file)
        except json.JSONDecodeError as e:
            raise json.JSONDecodeError(f"Error decoding JSON from {file_path}: {e.msg}", e.doc, e.pos)
    
    return results

def restructure_data(results):
    """
    å°†å•ä¸ªæ–‡ä»¶ä¸­çš„åŸå§‹æ•°æ®é‡ç»„ä¸ºæŒ‰é—®é¢˜åˆ†ç»„çš„æ ¼å¼ï¼Œå¹¶åªç­›é€‰ 'HEA' æ¨¡å‹çš„ç»“æœã€‚
    """
    questions_data = {}
    sample_sizes = sorted([int(s) for s in results.keys()])

    for size in sample_sizes:
        size_str = str(size)
        for model_name, questions in results[size_str].items():
            if not model_name.startswith('HEA'):
                continue
            
            for question_str, f1_score in questions.items():
                if question_str not in questions_data:
                    questions_data[question_str] = {'x': [], 'y': []}
                
                questions_data[question_str]['x'].append(size)
                questions_data[question_str]['y'].append(f1_score)
            
    return questions_data

# --- ç»˜å›¾å‡½æ•° (å·²é‡æ„) ---

def plot_all_in_one_figure(all_data, output_dir="fitting_curves"):
    """
    ä¸ºæ¯ä¸ªåˆ†ç±»ç±»å‹åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰é—®é¢˜å­å›¾çš„å¤§å›¾ã€‚
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created directory: {output_dir}")

    # éå†æ¯ä¸ªåˆ†ç±»ç±»å‹ (e.g., '2class', '5class')
    for class_type, questions in all_data.items():
        print(f"\nProcessing classification type: {class_type}...")
        
        # åˆ›å»ºä¸€ä¸ª 4x4 çš„å­å›¾ç½‘æ ¼
        fig, axes = plt.subplots(4, 4, figsize=(20, 18), constrained_layout=True)
        fig.suptitle(f'F1-Score vs. Sample Size (Model: GBAN, Type: {class_type})', fontsize=24)
        
        # å°†2Dçš„axesæ•°ç»„æ‰å¹³åŒ–ä¸º1Dï¼Œæ–¹ä¾¿éå†
        axes = axes.flatten()
        
        # å¯¹é—®é¢˜è¿›è¡Œæ’åºï¼Œç¡®ä¿ç»˜å›¾é¡ºåºä¸€è‡´
        sorted_questions = sorted(questions.items(), key=lambda item: int(item[0]))

        # éå†16ä¸ªé—®é¢˜å¹¶å¡«å……å­å›¾
        for i, (question, values) in enumerate(sorted_questions):
            if i >= len(axes): break # é˜²æ­¢é—®é¢˜æ•°è¶…è¿‡å­å›¾æ•°
            
            ax = axes[i]
            x_data = np.array(values['x'])
            y_data = np.array(values['y'])
            popt, _ = weighted_curve_fit(x_data, y_data)
            
            ax.scatter(x_data, y_data, label='Original Data', color='red', zorder=5, s=20)

            if popt is not None:
                x_fit = np.linspace(min(x_data), max(x_data) * 1.1, 200)
                y_fit = inverse_power_law(x_fit, *popt)
                ax.plot(x_fit, y_fit, label='Fitted Curve', color='blue', linewidth=2)
                
                param_text = f'a={popt[0]:.2f}, b={popt[1]:.2f}, c={popt[2]:.2f}'
                target_f1_score = 0.75
                predicted_size = predict_sample_size(popt, target_f1_score)
                
                prediction_text = f'\nPred. size for F1={target_f1_score}: '
                if predicted_size is not None:
                    prediction_text += f'{predicted_size:.0f}' if isinstance(predicted_size, (int, float)) else predicted_size
                else:
                    prediction_text += 'N/A'

                ax.text(0.05, 0.95, param_text + prediction_text, transform=ax.transAxes,
                         fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round,pad=0.3', fc='wheat', alpha=0.6))

            ax.set_title(f'Question: {question}', fontsize=14)
            ax.set_xlabel('Sample Size', fontsize=10)
            ax.set_ylabel('F1-Score', fontsize=10)
            ax.grid(True, which='both', linestyle='--', linewidth=0.5)
            ax.legend(fontsize=8)

        # éšè—å¤šä½™çš„å­å›¾
        for j in range(i + 1, len(axes)):
            axes[j].axis('off')

        # ä¿å­˜æ•´ä¸ªå›¾è¡¨
        file_name = f"HEA_{class_type}_all_questions.png"
        save_path = os.path.join(output_dir, file_name)
        plt.savefig(save_path, dpi=300)
        plt.close(fig)

        print(f"  - Saved consolidated plot to {save_path}")

# --- ä¸»æ‰§è¡Œå‡½æ•° ---

def main():
    """
    ä¸»å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæµç¨‹ï¼šè¯»å– -> é‡ç»„ -> ç»˜å›¾ã€‚
    """
    data_folder = 'size_experiment'
    experiment_files = {
        '2class': 'experiment_results_2.json',
        '5class': 'experiment_results_5.json'
    }
    
    all_structured_data = {}

    for class_type, file_name in experiment_files.items():
        file_path = os.path.join(data_folder, file_name)
        try:
            print(f"Reading data for '{class_type}' from {file_path}...")
            raw_results = read_experiment_results(file_path)
            structured_data = restructure_data(raw_results)
            all_structured_data[class_type] = structured_data
        except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
            print(f"\nAn error occurred while processing {file_name}: {e}")
            print("Please ensure the file exists and is correctly formatted.")
            continue
    
    if not all_structured_data:
        print("\nNo data was successfully processed. Exiting.")
        return
        
    plot_all_in_one_figure(all_structured_data)
    
    print("\nAll plots have been generated and saved successfully! ğŸ‰")

if __name__ == "__main__":
    main()
